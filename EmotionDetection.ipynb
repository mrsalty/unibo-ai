{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrsalty/unibo-ai/blob/main/EmotionDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzx0QkxOgID_"
      },
      "source": [
        "# Emotion Detection \n",
        "\n",
        "## Task \n",
        "\n",
        "The task consists in creating a Emotion Detection model, able to recognise the emotion expressed in a given text/sentence. \n",
        "\n",
        "We are expected to use `f1-macro average` metric to avaluate our models."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n",
        "To approach this task several architectures have been considered. \n",
        "\n",
        "The ideal and natural approach would be to use a **Transformer** architecture, which is kind of the state of the art in the NLP field. \n",
        "\n",
        "After a bit of experiments though this approach revealed to require big pre-trained models (such as BERT-like architectures) with hundred(s) of million parameters for training.\n",
        "\n",
        "\n",
        "Alternative architectures have been therefore considered which don't require such massive models and resources.\n",
        "\n",
        "\n",
        "**LSTM** and **GRU** are similar architectures, both very performing in NLP field, and they don't require such massive resources.\n",
        "\n",
        "\n",
        "This notebook is an approach the the problem using these architectures with an analysis of the performance obtained.\n",
        "\n"
      ],
      "metadata": {
        "id": "X08pohra9VVh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjH-Oz3cgQeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6996264a-355d-4214-b318-d1165f56faac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 353
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Bidirectional, Input, GRU\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import models, layers, backend as K\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize\n",
        "from numpy import array, asarray, zeros\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
        "from sklearn.utils import class_weight \n",
        "\n",
        "# download nltk resources\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global params\n",
        "VOCAB_SIZE = 5000\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "6KVJkPHHIaLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H85kp19OXwjK"
      },
      "source": [
        "# Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gceWqnephvyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce4cae9e-bdba-4b31-c37d-34488c376c9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  if __name__ == '__main__':\n"
          ]
        }
      ],
      "source": [
        "# load data from files\n",
        "train_ds = pd.read_csv(\"train_ekmann.csv\")\n",
        "test_ds = pd.read_csv(\"test_ekmann.csv\")\n",
        "val_ds = pd.read_csv(\"val_ekmann.csv\")\n",
        "\n",
        "# remove Id column\n",
        "train_ds = train_ds.drop('Id', 1)\n",
        "test_ds = test_ds.drop('Id', 1)\n",
        "val_ds = val_ds.drop('Id', 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrJV7ViS2mxJ"
      },
      "source": [
        "# Data visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3viA3N7rlJ_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fed1b07-fad5-487c-c41d-ff60ef33b3cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43410, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ],
      "source": [
        "train_ds.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.head"
      ],
      "metadata": {
        "id": "_HaXK4j2-f4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6726aaeb-9316-47ba-a6d1-fb0eff35c4be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                     Text   Emotion\n",
              "0      My favourite food is anything I didn't have to...   neutral\n",
              "1      Now if he does off himself, everyone will thin...   neutral\n",
              "2                         WHY THE FUCK IS BAYLESS ISOING     anger\n",
              "3                            To make her feel threatened      fear\n",
              "4                                 Dirty Southern Wankers     anger\n",
              "...                                                  ...       ...\n",
              "43405  Added you mate well I’ve just got the bow and ...       joy\n",
              "43406  Always thought that was funny but is it a refe...  surprise\n",
              "43407  What are you talking about? Anything bad that ...     anger\n",
              "43408            More like a baptism, with sexy results!       joy\n",
              "43409                                    Enjoy the ride!       joy\n",
              "\n",
              "[43410 rows x 2 columns]>"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48mrQEkwmC53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b22cc60-4058-4926-a89b-ec7f7ac06d16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f469ce78a90>"
            ]
          },
          "metadata": {},
          "execution_count": 358
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# emotion distribution\n",
        "sns.countplot(x='Emotion', data=train_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owmpa2S9IvZ6"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Visually analysing the data shows the need for some preprocessing. \n",
        "\n",
        "We proceed first removing punctuation and numbers, multiple spaces and converting to lower case.\n",
        "\n",
        "We then apply `lemmatization` which considers a language’s full vocabulary to apply a morphological analysis to words. The lemma is then a common way to represent morphological similar words (eg: 'studies' and 'studying' will be lemmatized to 'study').\n",
        "\n",
        "The text is now ready to be `tokenized`, so an index is assigned to each word and then the text is translated into an array of indexes. We then pad all datasets to the maximum length found so they all have the same number of columns.\n",
        "\n",
        "As last step we then, after having mapped each class into an integer, `hot encode` all three prediction datasets, so to model our output layers with dimension 7.\n",
        "\n",
        "It's worth observing that because we are provided of the three datasets for training, validation and test we will apply the same preprocessing to all of them, as much as we would apply preprocessing to the entire dataset before doing the `train_test_split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgOrreQ3IvZ6"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(sentence):\n",
        "    # to lower case\n",
        "    sentence = sentence.lower()\n",
        "    # remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "    # removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaSSHci9iIpF"
      },
      "outputs": [],
      "source": [
        "# lemmatize\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEJDlv58IvZ7"
      },
      "outputs": [],
      "source": [
        "def map_emotion(emotion):\n",
        "    if emotion == \"neutral\":\n",
        "        return 0\n",
        "    elif emotion == \"anger\":\n",
        "        return 1\n",
        "    elif emotion == \"sadness\":\n",
        "        return 2\n",
        "    elif emotion == \"fear\":\n",
        "        return 3\n",
        "    elif emotion == \"disgust\":\n",
        "        return 4\n",
        "    elif emotion == \"surprise\":\n",
        "        return 5\n",
        "    elif emotion == \"joy\":\n",
        "        return 6\n",
        "    else:\n",
        "      return -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adZtmENoIvZ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdb0dfa-7405-4930-b2af-0d51056ac8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'favourite', 'food', 'is', 'anything', 'i', 'didn', 't', 'have', 'to', 'cook', 'myself']\n",
            "['i', 'm', 'really', 'sorry', 'about', 'your', 'situation', 'although', 'i', 'love', 'the', 'name', 'sapphira', 'cirilla', 'and', 'scarlett']\n",
            "['is', 'this', 'in', 'new', 'orleans', 'i', 'really', 'feel', 'like', 'this', 'is', 'new', 'orleans']\n"
          ]
        }
      ],
      "source": [
        "# preprocess all dataframes\n",
        "train_ds['Text'] = train_ds['Text'].apply(lambda x: preprocess_text(x))\n",
        "train_ds['Text'] = train_ds['Text'].apply(lambda x: lemmatize(x))\n",
        "print(train_ds['Text'][0])\n",
        "\n",
        "test_ds['Text'] = test_ds['Text'].apply(lambda x: preprocess_text(x))\n",
        "test_ds['Text'] = test_ds['Text'].apply(lambda x: lemmatize(x))\n",
        "print(test_ds['Text'][0])\n",
        "\n",
        "val_ds['Text'] = val_ds['Text'].apply(lambda x: preprocess_text(x))\n",
        "val_ds['Text'] = val_ds['Text'].apply(lambda x: lemmatize(x))\n",
        "print(val_ds['Text'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-WXt65cIvZ7"
      },
      "outputs": [],
      "source": [
        "# prepare arrays for model\n",
        "y_train = train_ds['Emotion'].values.tolist()\n",
        "y_train = np.array(list(map(lambda x: map_emotion(x), y_train)))\n",
        "X_train = train_ds[\"Text\"].values.tolist()\n",
        "\n",
        "y_test = test_ds['Emotion'].values.tolist()\n",
        "y_test = np.array(list(map(lambda x: map_emotion(x), y_test)))\n",
        "X_test = test_ds[\"Text\"].values.tolist()\n",
        "\n",
        "y_val = val_ds['Emotion'].values.tolist()\n",
        "y_val = np.array(list(map(lambda x: map_emotion(x), y_val)))\n",
        "X_val = val_ds[\"Text\"].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_e2_yKaWPLjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec591484-1b79-445d-d0f9-958ea0c17622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitted tokenizer on 43410 documents\n",
            "Top 5 most common words are: [('i', 20778), ('the', 18003), ('a', 14536), ('to', 12600), ('you', 11459)]\n",
            "\"['my', 'favourite', 'food', 'is', 'anything', 'i', 'didn', 't', 'have', 'to', 'cook', 'myself']\" is converted into [18, 1061, 471, 9, 202, 1, 112, 14, 26, 4, 2784, 350]\n"
          ]
        }
      ],
      "source": [
        "# initialize tokenizer on train set \n",
        "tk = Tokenizer(num_words=VOCAB_SIZE,\n",
        "               filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "               lower=True,\n",
        "               split=\" \")\n",
        "tk.fit_on_texts(X_train)\n",
        "print('Fitted tokenizer on {} documents'.format(tk.document_count))\n",
        "print('Top 5 most common words are:', collections.Counter(tk.word_counts).most_common(5))\n",
        "\n",
        "# transform words in sequences of int\n",
        "X_train_seq = tk.texts_to_sequences(X_train)\n",
        "X_test_seq = tk.texts_to_sequences(X_test)\n",
        "X_val_seq = tk.texts_to_sequences(X_val)\n",
        "\n",
        "print('\"{}\" is converted into {}'.format(X_train[0], X_train_seq[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqpsbSMuEOJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b6c69d-f724-42e6-e6bb-da43ea67e0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes before padding:\n",
            "(43410, 32)\n",
            "(5427, 30)\n",
            "(5426, 30)\n",
            "32\n",
            "Shapes after padding:\n",
            "(43410, 32)\n",
            "(5427, 32)\n",
            "(5426, 32)\n"
          ]
        }
      ],
      "source": [
        "# padding each array to max lenght of sequences within the array\n",
        "X_train_seq = tf.keras.preprocessing.sequence.pad_sequences(X_train_seq, padding=\"post\")\n",
        "X_test_seq = tf.keras.preprocessing.sequence.pad_sequences(X_test_seq, padding=\"post\")\n",
        "X_val_seq = tf.keras.preprocessing.sequence.pad_sequences(X_val_seq, padding=\"post\")\n",
        "\n",
        "print(\"Shapes before padding:\")\n",
        "print(X_train_seq.shape)\n",
        "print(X_test_seq.shape)\n",
        "print(X_val_seq.shape)\n",
        "\n",
        "# pad each array to the longest of the three arrays so they are all same length\n",
        "max_padding = max(max(X_train_seq.shape[1], X_test_seq.shape[1]), X_val_seq.shape[1])\n",
        "print(max_padding)\n",
        "\n",
        "if (X_train_seq.shape[1] < max_padding):\n",
        "    padding_val_train = max_padding - X_train_seq.shape[1] \n",
        "    X_train_seq = np.pad(X_train_seq, [(0, 0), (0, padding_val_train)], mode='constant', constant_values=0)\n",
        "\n",
        "if (X_test_seq.shape[1] < max_padding):\n",
        "    padding_val_test = max_padding - X_test_seq.shape[1]\n",
        "    X_test_seq = np.pad(X_test_seq, [(0, 0), (0, padding_val_test)], mode='constant', constant_values=0)\n",
        "\n",
        "if (X_val_seq.shape[1] < max_padding):\n",
        "    padding_val_val = max_padding - X_val_seq.shape[1] \n",
        "    X_val_seq = np.pad(X_val_seq, [(0, 0), (0, padding_val_val)], mode='constant', constant_values=0)\n",
        "\n",
        "print(\"Shapes after padding:\")\n",
        "print(X_train_seq.shape)\n",
        "print(X_test_seq.shape)\n",
        "print(X_val_seq.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrWPFgwwRk_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5229634-d218-4d9a-d3c1-7c4ccd91222e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eg: 5 -> [0. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ],
      "source": [
        "# one hot encoding\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_test_oh = to_categorical(y_test)\n",
        "y_val_oh = to_categorical(y_val)\n",
        "\n",
        "print('eg: {} -> {}'.format(y_train[10], y_train_oh[10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3vTI72pFPg-"
      },
      "source": [
        "# Bidirectional LSTM\n",
        "\n",
        "A Bidirectional LSTM (Long Short Term Memory) is a RNN used primarily on NLP. Unlike standard LSTM, the input flows in both directions. It’s a powerful tool for modelling the sequential dependencies between words and phrases in both directions of the sequence. For these reasons this model was chosen as appropriate for this task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build model\n",
        "\n",
        "The architecture is composed of an `Embedding` layer: this layer enables us to convert each word into a fixed length vector of defined size. The resultant vector is a `Dense` layer which has real values. The fixed length of word vectors helps to represent words in a better way along with reduced dimensions.\n",
        "\n",
        "We then apply a strong (0.8) `Dropout` layer which helps avoiding a fast overfitting of the model. \n",
        "\n",
        "Two `bidirectional LSTM` layers of same size are then applied to then feed the output layer, a `Dense` layer with activation `softmax` which normalizes the output of our distribution to each class.\n",
        "\n",
        "We use an `EarlyStopping` callback with pretty low patience, as the model with the training dataset (pretty small in size) tends to overfit very quickly, so we expect this to run in quite few epochs."
      ],
      "metadata": {
        "id": "EqO-oyrgaGT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(max_padding,))\n",
        "x = Embedding(input_dim=VOCAB_SIZE,output_dim=256, input_length=max_padding)(input)\n",
        "x = Dropout(0.8)(x)\n",
        "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "x = Bidirectional(LSTM(128))(x)\n",
        "x = Dense(7, activation='softmax')(x)\n",
        "model_lstm = Model(inputs=input, outputs=x)\n",
        "model_lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHtaRDuwGP_s",
        "outputId": "0bbe827f-96eb-4998-a14a-3a31f7c774eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_33 (InputLayer)       [(None, 32)]              0         \n",
            "                                                                 \n",
            " embedding_32 (Embedding)    (None, 32, 256)           1280000   \n",
            "                                                                 \n",
            " dropout_32 (Dropout)        (None, 32, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_32 (Bidirecti  (None, 32, 256)          394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_33 (Bidirecti  (None, 256)              394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,070,279\n",
            "Trainable params: 2,070,279\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-xBBhtqS1CK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4adde006-c1a1-4f82-d8d3-9fe538280a0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "679/679 [==============================] - 16s 15ms/step - loss: 1.2777 - accuracy: 0.5270 - val_loss: 1.0785 - val_accuracy: 0.6119\n",
            "Epoch 2/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 1.0638 - accuracy: 0.6114 - val_loss: 1.0004 - val_accuracy: 0.6369\n",
            "Epoch 3/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 0.9892 - accuracy: 0.6396 - val_loss: 0.9812 - val_accuracy: 0.6373\n",
            "Epoch 4/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 0.9473 - accuracy: 0.6531 - val_loss: 0.9743 - val_accuracy: 0.6358\n",
            "Epoch 5/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 0.9149 - accuracy: 0.6660 - val_loss: 0.9717 - val_accuracy: 0.6441\n",
            "Epoch 6/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 0.8896 - accuracy: 0.6711 - val_loss: 0.9716 - val_accuracy: 0.6380\n",
            "Epoch 7/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 0.8633 - accuracy: 0.6818 - val_loss: 0.9750 - val_accuracy: 0.6395\n",
            "Epoch 8/20\n",
            "679/679 [==============================] - 9s 13ms/step - loss: 0.8396 - accuracy: 0.6879 - val_loss: 0.9794 - val_accuracy: 0.6358\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ],
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience = 2, verbose=1)\n",
        "\n",
        "model_lstm.compile(optimizer='adam'\n",
        "                    , loss='categorical_crossentropy'\n",
        "                    , metrics=['accuracy'])\n",
        "\n",
        "history_lstm = model_lstm.fit(X_train_seq\n",
        "                    , y_train_oh\n",
        "                    , epochs=NUM_EPOCHS\n",
        "                    , batch_size=BATCH_SIZE\n",
        "                    , validation_data=(X_val_seq, y_val_oh)\n",
        "                    , verbose=1\n",
        "                    , callbacks=[early_stopping_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction and scores"
      ],
      "metadata": {
        "id": "2i7YHRP9FQwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPwS2vhsJEj1"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = y_test_oh, model_lstm.predict(X_test_seq)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.unique(train_ds[\"Emotion\"])\n",
        "\n",
        "# hot encode y_pred\n",
        "y_pred_cat = to_categorical(np.argmax(y_pred, axis=1), 7)\n",
        "\n",
        "# classification report\n",
        "print(\"Classification report (LSTM):\")\n",
        "print()\n",
        "print(classification_report(y_true, y_pred_cat, target_names=class_names))\n",
        "\n",
        "# f1 macro score\n",
        "print(\"Macro avg f1 score:\", f1_score(y_true, y_pred_cat, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgotBj7VGuNy",
        "outputId": "ec0d502e-3165-4521-f19c-083113226bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (LSTM):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.59      0.68      0.63      1648\n",
            "     disgust       0.49      0.45      0.47       572\n",
            "        fear       0.59      0.53      0.56       355\n",
            "         joy       0.66      0.68      0.67        81\n",
            "     neutral       0.67      0.39      0.49       116\n",
            "     sadness       0.56      0.45      0.50       677\n",
            "    surprise       0.77      0.77      0.77      1978\n",
            "\n",
            "   micro avg       0.64      0.64      0.64      5427\n",
            "   macro avg       0.62      0.56      0.58      5427\n",
            "weighted avg       0.64      0.64      0.64      5427\n",
            " samples avg       0.64      0.64      0.64      5427\n",
            "\n",
            "Macro avg f1 score: 0.5840724056046386\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL30bLLnYPvf"
      },
      "source": [
        "# GRU\n",
        "\n",
        "GRU (Gated Recurrent Unit) are very similar to LSTM with a forget gate, but they have fewer parameters, as they don't implement an output gate."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model\n",
        "\n",
        "The architecture is composed of a first `Embedding` layer.\n",
        "\n",
        "We then apply a strong `Dropout` (0.8) which helps avoiding fast overfitting of the model. \n",
        "\n",
        "A `GRU` layer is then applied followed by two `Dense` layers of same size, the last with `Relu` activation function before feeding the output layer."
      ],
      "metadata": {
        "id": "VtwRQ2Q1aMPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Input(shape=(max_padding,))\n",
        "x = Embedding(input_dim=VOCAB_SIZE,output_dim=256, input_length=max_padding)(input)\n",
        "x = Dropout(0.8)(x)\n",
        "x = GRU(256)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(7, activation='softmax')(x)\n",
        "model_gru = Model(inputs=input, outputs=x)\n",
        "model_gru.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca47e96-6b9d-4db1-baeb-1893abe855b8",
        "id": "8Vbiqm1tYPvo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_34 (InputLayer)       [(None, 32)]              0         \n",
            "                                                                 \n",
            " embedding_33 (Embedding)    (None, 32, 256)           1280000   \n",
            "                                                                 \n",
            " dropout_33 (Dropout)        (None, 32, 256)           0         \n",
            "                                                                 \n",
            " gru_16 (GRU)                (None, 256)               394752    \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,742,343\n",
            "Trainable params: 1,742,343\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed709eba-5202-4938-9c6b-09d67fa255b9",
        "id": "4pC0zc6IYPvo"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "679/679 [==============================] - 6s 7ms/step - loss: 1.4632 - accuracy: 0.4185 - val_loss: 1.2090 - val_accuracy: 0.5628\n",
            "Epoch 2/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 1.1789 - accuracy: 0.5703 - val_loss: 1.1029 - val_accuracy: 0.6025\n",
            "Epoch 3/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 1.0705 - accuracy: 0.6113 - val_loss: 1.0277 - val_accuracy: 0.6264\n",
            "Epoch 4/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 1.0001 - accuracy: 0.6363 - val_loss: 1.0055 - val_accuracy: 0.6351\n",
            "Epoch 5/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 0.9553 - accuracy: 0.6531 - val_loss: 0.9803 - val_accuracy: 0.6406\n",
            "Epoch 6/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 0.9173 - accuracy: 0.6642 - val_loss: 0.9751 - val_accuracy: 0.6390\n",
            "Epoch 7/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 0.8876 - accuracy: 0.6743 - val_loss: 0.9797 - val_accuracy: 0.6382\n",
            "Epoch 8/20\n",
            "679/679 [==============================] - 4s 6ms/step - loss: 0.8681 - accuracy: 0.6809 - val_loss: 1.0010 - val_accuracy: 0.6369\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ],
      "source": [
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience = 2, verbose=1)\n",
        "\n",
        "model_gru.compile(optimizer='adam'\n",
        "                    , loss='categorical_crossentropy'\n",
        "                    , metrics=['accuracy'])\n",
        "\n",
        "history_gru = model_gru.fit(X_train_seq\n",
        "                    , y_train_oh\n",
        "                    , epochs=NUM_EPOCHS\n",
        "                    , batch_size=BATCH_SIZE\n",
        "                    , validation_data=(X_val_seq, y_val_oh)\n",
        "                    , verbose=1\n",
        "                    , callbacks=[early_stopping_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction and scores"
      ],
      "metadata": {
        "id": "nSknfIgrYPvp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeWFCWpVYPvp"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = y_test_oh, model_gru.predict(X_test_seq)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = np.unique(train_ds[\"Emotion\"])\n",
        "\n",
        "# hot encode y_pred\n",
        "y_pred_cat = to_categorical(np.argmax(y_pred, axis=1), 7)\n",
        "\n",
        "# classification report\\\n",
        "print(\"Classification report (GRU):\")\n",
        "print()\n",
        "print(classification_report(y_true, y_pred_cat, target_names=class_names))\n",
        "\n",
        "# f1 macro score\n",
        "print(\"Macro avg f1 score:\", f1_score(y_true, y_pred_cat, average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b98fc375-207e-45ce-b83d-27db368258fc",
        "id": "dpcURT0-YPvp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report (GRU):\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.57      0.73      0.64      1648\n",
            "     disgust       0.53      0.42      0.47       572\n",
            "        fear       0.66      0.51      0.58       355\n",
            "         joy       0.74      0.59      0.66        81\n",
            "     neutral       0.61      0.46      0.52       116\n",
            "     sadness       0.56      0.45      0.50       677\n",
            "    surprise       0.80      0.76      0.78      1978\n",
            "\n",
            "   micro avg       0.65      0.65      0.65      5427\n",
            "   macro avg       0.64      0.56      0.59      5427\n",
            "weighted avg       0.66      0.65      0.65      5427\n",
            " samples avg       0.65      0.65      0.65      5427\n",
            "\n",
            "Macro avg f1 score: 0.5917907309276702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusions\n",
        "\n",
        "The two models perform very similarly (as expected since their internal architecture is also alike) but after few runs we can observe slight better results obtained with the `GRU` model which as a plus also requires less parameters. "
      ],
      "metadata": {
        "id": "ZOBvtuhCFY-J"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "H85kp19OXwjK"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}